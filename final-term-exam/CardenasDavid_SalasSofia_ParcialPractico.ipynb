{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sofía Alejandra Salas Aquino\n",
    "# David Santiago Cárdenas Rivera\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "db_data = pd.read_csv('creditcard.csv')\n",
    "db_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = db_data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "284315\n"
     ]
    }
   ],
   "source": [
    "fraud = 0\n",
    "nofraud = 0\n",
    "\n",
    "for classs in y:\n",
    "    if classs == 1:\n",
    "        fraud += 1\n",
    "    else:\n",
    "        nofraud += 1\n",
    "print(fraud)\n",
    "print(nofraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fraud_df = []\n",
    "fraud_df = []\n",
    "max_limit = 700\n",
    "i = 0\n",
    "no_fraud_quantity = 0\n",
    "\n",
    "while True:\n",
    "    if no_fraud_quantity > 700:\n",
    "        break\n",
    "    if(db_data.loc[i][\"Class\"] == 0):\n",
    "        no_fraud_df.append(db_data.loc[i])\n",
    "        no_fraud_quantity += 1\n",
    "    i+=1\n",
    "\n",
    "fraud_quantity = 0\n",
    "\n",
    "for i in range(len(db_data)):\n",
    "    if fraud_quantity == 492:\n",
    "        break\n",
    "    if(db_data.loc[i][\"Class\"] == 1):\n",
    "        fraud_df.append(db_data.loc[i])\n",
    "        fraud_quantity+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>528.0</td>\n",
       "      <td>-0.378417</td>\n",
       "      <td>0.751515</td>\n",
       "      <td>1.772256</td>\n",
       "      <td>0.311020</td>\n",
       "      <td>-0.329130</td>\n",
       "      <td>-0.746206</td>\n",
       "      <td>0.719034</td>\n",
       "      <td>-0.081805</td>\n",
       "      <td>-0.152417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120891</td>\n",
       "      <td>-0.240394</td>\n",
       "      <td>-0.057803</td>\n",
       "      <td>0.733812</td>\n",
       "      <td>-0.049448</td>\n",
       "      <td>0.207357</td>\n",
       "      <td>0.023386</td>\n",
       "      <td>0.057469</td>\n",
       "      <td>25.41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>529.0</td>\n",
       "      <td>-2.000567</td>\n",
       "      <td>-2.495484</td>\n",
       "      <td>2.467149</td>\n",
       "      <td>1.140053</td>\n",
       "      <td>2.462010</td>\n",
       "      <td>0.594262</td>\n",
       "      <td>-2.110183</td>\n",
       "      <td>0.788347</td>\n",
       "      <td>0.958809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422452</td>\n",
       "      <td>1.195394</td>\n",
       "      <td>0.297836</td>\n",
       "      <td>-0.857105</td>\n",
       "      <td>-0.219322</td>\n",
       "      <td>0.861019</td>\n",
       "      <td>-0.124622</td>\n",
       "      <td>-0.171060</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>530.0</td>\n",
       "      <td>1.255931</td>\n",
       "      <td>0.317615</td>\n",
       "      <td>0.293256</td>\n",
       "      <td>0.697224</td>\n",
       "      <td>-0.413810</td>\n",
       "      <td>-1.081986</td>\n",
       "      <td>0.053119</td>\n",
       "      <td>-0.175252</td>\n",
       "      <td>0.108262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.293567</td>\n",
       "      <td>-0.871804</td>\n",
       "      <td>0.134498</td>\n",
       "      <td>0.326186</td>\n",
       "      <td>0.199886</td>\n",
       "      <td>0.096395</td>\n",
       "      <td>-0.026373</td>\n",
       "      <td>0.029732</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>530.0</td>\n",
       "      <td>-0.690417</td>\n",
       "      <td>1.322681</td>\n",
       "      <td>0.910911</td>\n",
       "      <td>0.112849</td>\n",
       "      <td>-0.356281</td>\n",
       "      <td>-1.044902</td>\n",
       "      <td>0.330444</td>\n",
       "      <td>0.387623</td>\n",
       "      <td>-0.471599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224965</td>\n",
       "      <td>-0.751207</td>\n",
       "      <td>0.061962</td>\n",
       "      <td>0.315721</td>\n",
       "      <td>-0.154944</td>\n",
       "      <td>0.076185</td>\n",
       "      <td>0.114245</td>\n",
       "      <td>0.034451</td>\n",
       "      <td>9.72</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>530.0</td>\n",
       "      <td>1.217261</td>\n",
       "      <td>-0.080646</td>\n",
       "      <td>-0.059293</td>\n",
       "      <td>-0.868862</td>\n",
       "      <td>-0.236628</td>\n",
       "      <td>-0.700159</td>\n",
       "      <td>0.143747</td>\n",
       "      <td>-0.111374</td>\n",
       "      <td>0.790809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081582</td>\n",
       "      <td>0.534693</td>\n",
       "      <td>-0.159644</td>\n",
       "      <td>0.296812</td>\n",
       "      <td>0.855793</td>\n",
       "      <td>-0.553063</td>\n",
       "      <td>0.054274</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1193 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541    406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623    472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108  6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329  7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "698    528.0 -0.378417  0.751515  1.772256  0.311020 -0.329130 -0.746206   \n",
       "699    529.0 -2.000567 -2.495484  2.467149  1.140053  2.462010  0.594262   \n",
       "700    530.0  1.255931  0.317615  0.293256  0.697224 -0.413810 -1.081986   \n",
       "701    530.0 -0.690417  1.322681  0.910911  0.112849 -0.356281 -1.044902   \n",
       "702    530.0  1.217261 -0.080646 -0.059293 -0.868862 -0.236628 -0.700159   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541  -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623   0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920  0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108 -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329  1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "698   0.719034 -0.081805 -0.152417  ... -0.120891 -0.240394 -0.057803   \n",
       "699  -2.110183  0.788347  0.958809  ...  0.422452  1.195394  0.297836   \n",
       "700   0.053119 -0.175252  0.108262  ... -0.293567 -0.871804  0.134498   \n",
       "701   0.330444  0.387623 -0.471599  ... -0.224965 -0.751207  0.061962   \n",
       "702   0.143747 -0.111374  0.790809  ...  0.081582  0.534693 -0.159644   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "541   0.320198  0.044519  0.177840  0.261145 -0.143276    0.00    1.0  \n",
       "623  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00    1.0  \n",
       "4920 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93    1.0  \n",
       "6108 -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00    1.0  \n",
       "6329 -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00    1.0  \n",
       "...        ...       ...       ...       ...       ...     ...    ...  \n",
       "698   0.733812 -0.049448  0.207357  0.023386  0.057469   25.41    0.0  \n",
       "699  -0.857105 -0.219322  0.861019 -0.124622 -0.171060    1.50    0.0  \n",
       "700   0.326186  0.199886  0.096395 -0.026373  0.029732    1.98    0.0  \n",
       "701   0.315721 -0.154944  0.076185  0.114245  0.034451    9.72    0.0  \n",
       "702   0.296812  0.855793 -0.553063  0.054274  0.001410    1.00    0.0  \n",
       "\n",
       "[1193 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_balanceado = fraud_df + no_fraud_df\n",
    "db_balanceado_df = pd.DataFrame(db_balanceado)\n",
    "db_balanceado_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_balanceado_df = db_balanceado_df.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_balanceado_df = db_balanceado_df.reset_index()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "total_atipicos=[]\n",
    "for column in db_balanceado_df:\n",
    "    if column == \"Class\":\n",
    "        continue\n",
    "\n",
    "    x_temp = db_balanceado_df[column]\n",
    "    q3=np.quantile(x_temp, 0.75)\n",
    "    q1=np.quantile(x_temp, 0.25)\n",
    "    limsp=q3+1.5*(q3-q1)\n",
    "    liminf=q1-1.5*(q3-q1)\n",
    "    for j in range(0, len(x_temp)):\n",
    "        if x_temp.iloc[j]>limsp:\n",
    "            if j not in total_atipicos:\n",
    "                total_atipicos.append(j)\n",
    "        if x_temp.iloc[j]<liminf:\n",
    "            if j not in total_atipicos:\n",
    "                total_atipicos.append(j)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "592"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_atipicos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = db_balanceado_df.drop(total_atipicos)\n",
    "X_new = X_new.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new.drop(['index'], axis=1)\n",
    "X_new = X_new.drop(['level_0'], axis=1)\n",
    "y = X_new['Class']\n",
    "X_new = X_new.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.377231</td>\n",
       "      <td>-0.212618</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>-0.199371</td>\n",
       "      <td>0.052546</td>\n",
       "      <td>-0.051761</td>\n",
       "      <td>-0.259057</td>\n",
       "      <td>0.213119</td>\n",
       "      <td>0.229072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.318033</td>\n",
       "      <td>-0.281309</td>\n",
       "      <td>-0.196420</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>-0.031837</td>\n",
       "      <td>0.553666</td>\n",
       "      <td>-0.040292</td>\n",
       "      <td>-0.145427</td>\n",
       "      <td>-0.027116</td>\n",
       "      <td>-0.050507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>-0.377231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.537160</td>\n",
       "      <td>0.544743</td>\n",
       "      <td>0.185181</td>\n",
       "      <td>-0.388342</td>\n",
       "      <td>-0.092635</td>\n",
       "      <td>0.265326</td>\n",
       "      <td>-0.460090</td>\n",
       "      <td>-0.613994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383434</td>\n",
       "      <td>0.293486</td>\n",
       "      <td>-0.111097</td>\n",
       "      <td>-0.127889</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>-0.160697</td>\n",
       "      <td>-0.063708</td>\n",
       "      <td>0.469521</td>\n",
       "      <td>0.273470</td>\n",
       "      <td>-0.310984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-0.212618</td>\n",
       "      <td>-0.537160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.504155</td>\n",
       "      <td>0.025525</td>\n",
       "      <td>0.528980</td>\n",
       "      <td>0.542456</td>\n",
       "      <td>-0.306339</td>\n",
       "      <td>0.431457</td>\n",
       "      <td>0.722074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206522</td>\n",
       "      <td>-0.313298</td>\n",
       "      <td>0.140931</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>0.201423</td>\n",
       "      <td>-0.271572</td>\n",
       "      <td>0.067682</td>\n",
       "      <td>-0.458994</td>\n",
       "      <td>-0.343049</td>\n",
       "      <td>0.081195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>0.091191</td>\n",
       "      <td>0.544743</td>\n",
       "      <td>-0.504155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.093753</td>\n",
       "      <td>-0.086007</td>\n",
       "      <td>-0.355961</td>\n",
       "      <td>0.326635</td>\n",
       "      <td>-0.302267</td>\n",
       "      <td>-0.391789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214640</td>\n",
       "      <td>0.223206</td>\n",
       "      <td>-0.032883</td>\n",
       "      <td>-0.035522</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.169180</td>\n",
       "      <td>-0.078656</td>\n",
       "      <td>0.356014</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>-0.138690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>-0.199371</td>\n",
       "      <td>0.185181</td>\n",
       "      <td>0.025525</td>\n",
       "      <td>0.093753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.559396</td>\n",
       "      <td>-0.220784</td>\n",
       "      <td>-0.027481</td>\n",
       "      <td>0.066488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084219</td>\n",
       "      <td>-0.274459</td>\n",
       "      <td>-0.163565</td>\n",
       "      <td>-0.146238</td>\n",
       "      <td>-0.386069</td>\n",
       "      <td>-0.099994</td>\n",
       "      <td>-0.195626</td>\n",
       "      <td>-0.102478</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>-0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>0.052546</td>\n",
       "      <td>-0.388342</td>\n",
       "      <td>0.528980</td>\n",
       "      <td>-0.086007</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164525</td>\n",
       "      <td>0.160968</td>\n",
       "      <td>0.278992</td>\n",
       "      <td>0.488596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216881</td>\n",
       "      <td>-0.125992</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>-0.094205</td>\n",
       "      <td>-0.444513</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>-0.009125</td>\n",
       "      <td>-0.219925</td>\n",
       "      <td>-0.215934</td>\n",
       "      <td>0.201458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>-0.051761</td>\n",
       "      <td>-0.092635</td>\n",
       "      <td>0.542456</td>\n",
       "      <td>-0.355961</td>\n",
       "      <td>0.559396</td>\n",
       "      <td>0.164525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.607770</td>\n",
       "      <td>0.263959</td>\n",
       "      <td>0.573996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134959</td>\n",
       "      <td>-0.521971</td>\n",
       "      <td>-0.149689</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>-0.190029</td>\n",
       "      <td>-0.106753</td>\n",
       "      <td>-0.449265</td>\n",
       "      <td>-0.357647</td>\n",
       "      <td>0.022993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-0.259057</td>\n",
       "      <td>0.265326</td>\n",
       "      <td>-0.306339</td>\n",
       "      <td>0.326635</td>\n",
       "      <td>-0.220784</td>\n",
       "      <td>0.160968</td>\n",
       "      <td>-0.607770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.226640</td>\n",
       "      <td>-0.450971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137628</td>\n",
       "      <td>0.247115</td>\n",
       "      <td>0.173057</td>\n",
       "      <td>0.041328</td>\n",
       "      <td>-0.259863</td>\n",
       "      <td>-0.073169</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.389636</td>\n",
       "      <td>0.318754</td>\n",
       "      <td>-0.023768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.213119</td>\n",
       "      <td>-0.460090</td>\n",
       "      <td>0.431457</td>\n",
       "      <td>-0.302267</td>\n",
       "      <td>-0.027481</td>\n",
       "      <td>0.278992</td>\n",
       "      <td>0.263959</td>\n",
       "      <td>-0.226640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.258399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>-0.246892</td>\n",
       "      <td>0.108230</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.062905</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>-0.316286</td>\n",
       "      <td>-0.312400</td>\n",
       "      <td>0.021961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.229072</td>\n",
       "      <td>-0.613994</td>\n",
       "      <td>0.722074</td>\n",
       "      <td>-0.391789</td>\n",
       "      <td>0.066488</td>\n",
       "      <td>0.488596</td>\n",
       "      <td>0.573996</td>\n",
       "      <td>-0.450971</td>\n",
       "      <td>0.258399</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.330711</td>\n",
       "      <td>-0.491226</td>\n",
       "      <td>0.045169</td>\n",
       "      <td>0.105025</td>\n",
       "      <td>0.084824</td>\n",
       "      <td>-0.070467</td>\n",
       "      <td>-0.010258</td>\n",
       "      <td>-0.517305</td>\n",
       "      <td>-0.389306</td>\n",
       "      <td>0.079090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>-0.069408</td>\n",
       "      <td>0.460996</td>\n",
       "      <td>-0.622217</td>\n",
       "      <td>0.366972</td>\n",
       "      <td>-0.062145</td>\n",
       "      <td>-0.331257</td>\n",
       "      <td>-0.481085</td>\n",
       "      <td>0.386819</td>\n",
       "      <td>-0.473168</td>\n",
       "      <td>-0.577891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258638</td>\n",
       "      <td>0.387545</td>\n",
       "      <td>-0.004765</td>\n",
       "      <td>0.042407</td>\n",
       "      <td>0.042191</td>\n",
       "      <td>0.011532</td>\n",
       "      <td>-0.081003</td>\n",
       "      <td>0.431903</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>-0.100133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.233383</td>\n",
       "      <td>-0.607920</td>\n",
       "      <td>0.723637</td>\n",
       "      <td>-0.494056</td>\n",
       "      <td>0.155256</td>\n",
       "      <td>0.480573</td>\n",
       "      <td>0.644262</td>\n",
       "      <td>-0.422350</td>\n",
       "      <td>0.507992</td>\n",
       "      <td>0.756915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339283</td>\n",
       "      <td>-0.469251</td>\n",
       "      <td>0.027774</td>\n",
       "      <td>0.096737</td>\n",
       "      <td>0.102180</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>-0.052746</td>\n",
       "      <td>-0.541412</td>\n",
       "      <td>-0.371929</td>\n",
       "      <td>0.064159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>0.125400</td>\n",
       "      <td>-0.031464</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.090602</td>\n",
       "      <td>-0.003248</td>\n",
       "      <td>-0.027450</td>\n",
       "      <td>0.053043</td>\n",
       "      <td>-0.242191</td>\n",
       "      <td>-0.058788</td>\n",
       "      <td>0.069906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145848</td>\n",
       "      <td>-0.085179</td>\n",
       "      <td>0.017067</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>-0.049906</td>\n",
       "      <td>0.050820</td>\n",
       "      <td>0.046721</td>\n",
       "      <td>-0.097055</td>\n",
       "      <td>-0.009827</td>\n",
       "      <td>0.071644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>0.133059</td>\n",
       "      <td>-0.606714</td>\n",
       "      <td>0.773571</td>\n",
       "      <td>-0.548988</td>\n",
       "      <td>0.050585</td>\n",
       "      <td>0.439396</td>\n",
       "      <td>0.616490</td>\n",
       "      <td>-0.351765</td>\n",
       "      <td>0.442819</td>\n",
       "      <td>0.833678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.394361</td>\n",
       "      <td>-0.402651</td>\n",
       "      <td>0.032559</td>\n",
       "      <td>0.150149</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>-0.109379</td>\n",
       "      <td>-0.025513</td>\n",
       "      <td>-0.544174</td>\n",
       "      <td>-0.364835</td>\n",
       "      <td>0.096556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>0.085176</td>\n",
       "      <td>-0.043697</td>\n",
       "      <td>0.023627</td>\n",
       "      <td>-0.183419</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>-0.121753</td>\n",
       "      <td>0.100351</td>\n",
       "      <td>-0.146436</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>0.076537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063127</td>\n",
       "      <td>-0.027921</td>\n",
       "      <td>-0.037556</td>\n",
       "      <td>0.178481</td>\n",
       "      <td>-0.118216</td>\n",
       "      <td>-0.091227</td>\n",
       "      <td>0.010227</td>\n",
       "      <td>0.029423</td>\n",
       "      <td>0.056418</td>\n",
       "      <td>0.018250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.298773</td>\n",
       "      <td>-0.259620</td>\n",
       "      <td>0.362196</td>\n",
       "      <td>-0.262224</td>\n",
       "      <td>0.265761</td>\n",
       "      <td>0.064874</td>\n",
       "      <td>0.561123</td>\n",
       "      <td>-0.396564</td>\n",
       "      <td>0.224211</td>\n",
       "      <td>0.547964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137428</td>\n",
       "      <td>-0.424934</td>\n",
       "      <td>-0.177923</td>\n",
       "      <td>-0.060972</td>\n",
       "      <td>0.016367</td>\n",
       "      <td>0.069206</td>\n",
       "      <td>0.023017</td>\n",
       "      <td>-0.400483</td>\n",
       "      <td>-0.168937</td>\n",
       "      <td>-0.070891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>0.261535</td>\n",
       "      <td>-0.320329</td>\n",
       "      <td>0.366770</td>\n",
       "      <td>-0.174088</td>\n",
       "      <td>0.398818</td>\n",
       "      <td>0.261353</td>\n",
       "      <td>0.615787</td>\n",
       "      <td>-0.329073</td>\n",
       "      <td>0.363619</td>\n",
       "      <td>0.530739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.331146</td>\n",
       "      <td>-0.529587</td>\n",
       "      <td>-0.069522</td>\n",
       "      <td>0.077769</td>\n",
       "      <td>0.021058</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>-0.036736</td>\n",
       "      <td>-0.402241</td>\n",
       "      <td>-0.229835</td>\n",
       "      <td>-0.037230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.087089</td>\n",
       "      <td>-0.041540</td>\n",
       "      <td>0.030698</td>\n",
       "      <td>-0.061092</td>\n",
       "      <td>0.195161</td>\n",
       "      <td>-0.086865</td>\n",
       "      <td>0.223365</td>\n",
       "      <td>-0.168181</td>\n",
       "      <td>0.007511</td>\n",
       "      <td>0.174440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173415</td>\n",
       "      <td>-0.300471</td>\n",
       "      <td>-0.146002</td>\n",
       "      <td>-0.180608</td>\n",
       "      <td>-0.050355</td>\n",
       "      <td>0.023086</td>\n",
       "      <td>-0.050457</td>\n",
       "      <td>-0.126527</td>\n",
       "      <td>-0.014515</td>\n",
       "      <td>-0.008742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>-0.224958</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.044979</td>\n",
       "      <td>-0.021438</td>\n",
       "      <td>-0.205620</td>\n",
       "      <td>0.011880</td>\n",
       "      <td>-0.107988</td>\n",
       "      <td>0.066067</td>\n",
       "      <td>0.001603</td>\n",
       "      <td>-0.023067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453322</td>\n",
       "      <td>0.160571</td>\n",
       "      <td>0.152852</td>\n",
       "      <td>-0.134813</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>-0.140213</td>\n",
       "      <td>-0.030405</td>\n",
       "      <td>0.102724</td>\n",
       "      <td>-0.049347</td>\n",
       "      <td>0.100247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>-0.318033</td>\n",
       "      <td>0.383434</td>\n",
       "      <td>-0.206522</td>\n",
       "      <td>0.214640</td>\n",
       "      <td>0.084219</td>\n",
       "      <td>-0.216881</td>\n",
       "      <td>-0.134959</td>\n",
       "      <td>0.137628</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>-0.330711</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243477</td>\n",
       "      <td>0.068996</td>\n",
       "      <td>-0.119468</td>\n",
       "      <td>-0.041165</td>\n",
       "      <td>-0.169757</td>\n",
       "      <td>0.033061</td>\n",
       "      <td>0.469465</td>\n",
       "      <td>0.155939</td>\n",
       "      <td>0.138114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>-0.281309</td>\n",
       "      <td>0.293486</td>\n",
       "      <td>-0.313298</td>\n",
       "      <td>0.223206</td>\n",
       "      <td>-0.274459</td>\n",
       "      <td>-0.125992</td>\n",
       "      <td>-0.521971</td>\n",
       "      <td>0.247115</td>\n",
       "      <td>-0.246892</td>\n",
       "      <td>-0.491226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.630101</td>\n",
       "      <td>-0.203057</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>-0.018456</td>\n",
       "      <td>-0.080676</td>\n",
       "      <td>0.344696</td>\n",
       "      <td>0.216135</td>\n",
       "      <td>0.085301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>-0.196420</td>\n",
       "      <td>-0.111097</td>\n",
       "      <td>0.140931</td>\n",
       "      <td>-0.032883</td>\n",
       "      <td>-0.163565</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>-0.149689</td>\n",
       "      <td>0.173057</td>\n",
       "      <td>0.108230</td>\n",
       "      <td>0.045169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068996</td>\n",
       "      <td>0.630101</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221019</td>\n",
       "      <td>0.035967</td>\n",
       "      <td>-0.075476</td>\n",
       "      <td>-0.158294</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>-0.079816</td>\n",
       "      <td>0.116273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.033627</td>\n",
       "      <td>-0.127889</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>-0.035522</td>\n",
       "      <td>-0.146238</td>\n",
       "      <td>-0.094205</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.041328</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.105025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119468</td>\n",
       "      <td>-0.203057</td>\n",
       "      <td>-0.221019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263934</td>\n",
       "      <td>-0.431161</td>\n",
       "      <td>0.133757</td>\n",
       "      <td>-0.050846</td>\n",
       "      <td>-0.038727</td>\n",
       "      <td>0.057335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.031837</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.201423</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>-0.386069</td>\n",
       "      <td>-0.444513</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>-0.259863</td>\n",
       "      <td>0.062905</td>\n",
       "      <td>0.084824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041165</td>\n",
       "      <td>0.063967</td>\n",
       "      <td>0.035967</td>\n",
       "      <td>0.263934</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.151414</td>\n",
       "      <td>0.107628</td>\n",
       "      <td>-0.092365</td>\n",
       "      <td>-0.038297</td>\n",
       "      <td>-0.057971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>0.553666</td>\n",
       "      <td>-0.160697</td>\n",
       "      <td>-0.271572</td>\n",
       "      <td>0.169180</td>\n",
       "      <td>-0.099994</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>-0.190029</td>\n",
       "      <td>-0.073169</td>\n",
       "      <td>0.063168</td>\n",
       "      <td>-0.070467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169757</td>\n",
       "      <td>-0.018456</td>\n",
       "      <td>-0.075476</td>\n",
       "      <td>-0.431161</td>\n",
       "      <td>-0.151414</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.188639</td>\n",
       "      <td>-0.036780</td>\n",
       "      <td>0.083193</td>\n",
       "      <td>-0.049407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-0.040292</td>\n",
       "      <td>-0.063708</td>\n",
       "      <td>0.067682</td>\n",
       "      <td>-0.078656</td>\n",
       "      <td>-0.195626</td>\n",
       "      <td>-0.009125</td>\n",
       "      <td>-0.106753</td>\n",
       "      <td>0.059990</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>-0.010258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033061</td>\n",
       "      <td>-0.080676</td>\n",
       "      <td>-0.158294</td>\n",
       "      <td>0.133757</td>\n",
       "      <td>0.107628</td>\n",
       "      <td>-0.188639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093488</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.074653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>-0.145427</td>\n",
       "      <td>0.469521</td>\n",
       "      <td>-0.458994</td>\n",
       "      <td>0.356014</td>\n",
       "      <td>-0.102478</td>\n",
       "      <td>-0.219925</td>\n",
       "      <td>-0.449265</td>\n",
       "      <td>0.389636</td>\n",
       "      <td>-0.316286</td>\n",
       "      <td>-0.517305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469465</td>\n",
       "      <td>0.344696</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>-0.050846</td>\n",
       "      <td>-0.092365</td>\n",
       "      <td>-0.036780</td>\n",
       "      <td>-0.093488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.652175</td>\n",
       "      <td>-0.117867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.027116</td>\n",
       "      <td>0.273470</td>\n",
       "      <td>-0.343049</td>\n",
       "      <td>0.252866</td>\n",
       "      <td>-0.106127</td>\n",
       "      <td>-0.215934</td>\n",
       "      <td>-0.357647</td>\n",
       "      <td>0.318754</td>\n",
       "      <td>-0.312400</td>\n",
       "      <td>-0.389306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155939</td>\n",
       "      <td>0.216135</td>\n",
       "      <td>-0.079816</td>\n",
       "      <td>-0.038727</td>\n",
       "      <td>-0.038297</td>\n",
       "      <td>0.083193</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.652175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>-0.050507</td>\n",
       "      <td>-0.310984</td>\n",
       "      <td>0.081195</td>\n",
       "      <td>-0.138690</td>\n",
       "      <td>-0.242000</td>\n",
       "      <td>0.201458</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>-0.023768</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.079090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138114</td>\n",
       "      <td>0.085301</td>\n",
       "      <td>0.116273</td>\n",
       "      <td>0.057335</td>\n",
       "      <td>-0.057971</td>\n",
       "      <td>-0.049407</td>\n",
       "      <td>0.074653</td>\n",
       "      <td>-0.117867</td>\n",
       "      <td>-0.039668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "V1      1.000000 -0.377231 -0.212618  0.091191 -0.199371  0.052546 -0.051761   \n",
       "V2     -0.377231  1.000000 -0.537160  0.544743  0.185181 -0.388342 -0.092635   \n",
       "V3     -0.212618 -0.537160  1.000000 -0.504155  0.025525  0.528980  0.542456   \n",
       "V4      0.091191  0.544743 -0.504155  1.000000  0.093753 -0.086007 -0.355961   \n",
       "V5     -0.199371  0.185181  0.025525  0.093753  1.000000  0.042962  0.559396   \n",
       "V6      0.052546 -0.388342  0.528980 -0.086007  0.042962  1.000000  0.164525   \n",
       "V7     -0.051761 -0.092635  0.542456 -0.355961  0.559396  0.164525  1.000000   \n",
       "V8     -0.259057  0.265326 -0.306339  0.326635 -0.220784  0.160968 -0.607770   \n",
       "V9      0.213119 -0.460090  0.431457 -0.302267 -0.027481  0.278992  0.263959   \n",
       "V10     0.229072 -0.613994  0.722074 -0.391789  0.066488  0.488596  0.573996   \n",
       "V11    -0.069408  0.460996 -0.622217  0.366972 -0.062145 -0.331257 -0.481085   \n",
       "V12     0.233383 -0.607920  0.723637 -0.494056  0.155256  0.480573  0.644262   \n",
       "V13     0.125400 -0.031464 -0.000696 -0.090602 -0.003248 -0.027450  0.053043   \n",
       "V14     0.133059 -0.606714  0.773571 -0.548988  0.050585  0.439396  0.616490   \n",
       "V15     0.085176 -0.043697  0.023627 -0.183419  0.014516 -0.121753  0.100351   \n",
       "V16     0.298773 -0.259620  0.362196 -0.262224  0.265761  0.064874  0.561123   \n",
       "V17     0.261535 -0.320329  0.366770 -0.174088  0.398818  0.261353  0.615787   \n",
       "V18     0.087089 -0.041540  0.030698 -0.061092  0.195161 -0.086865  0.223365   \n",
       "V19    -0.224958  0.052927  0.044979 -0.021438 -0.205620  0.011880 -0.107988   \n",
       "V20    -0.318033  0.383434 -0.206522  0.214640  0.084219 -0.216881 -0.134959   \n",
       "V21    -0.281309  0.293486 -0.313298  0.223206 -0.274459 -0.125992 -0.521971   \n",
       "V22    -0.196420 -0.111097  0.140931 -0.032883 -0.163565  0.270270 -0.149689   \n",
       "V23     0.033627 -0.127889  0.038129 -0.035522 -0.146238 -0.094205  0.005679   \n",
       "V24    -0.031837  0.004079  0.201423  0.032609 -0.386069 -0.444513  0.054669   \n",
       "V25     0.553666 -0.160697 -0.271572  0.169180 -0.099994 -0.004464 -0.190029   \n",
       "V26    -0.040292 -0.063708  0.067682 -0.078656 -0.195626 -0.009125 -0.106753   \n",
       "V27    -0.145427  0.469521 -0.458994  0.356014 -0.102478 -0.219925 -0.449265   \n",
       "V28    -0.027116  0.273470 -0.343049  0.252866 -0.106127 -0.215934 -0.357647   \n",
       "Amount -0.050507 -0.310984  0.081195 -0.138690 -0.242000  0.201458  0.022993   \n",
       "\n",
       "              V8        V9       V10  ...       V20       V21       V22  \\\n",
       "V1     -0.259057  0.213119  0.229072  ... -0.318033 -0.281309 -0.196420   \n",
       "V2      0.265326 -0.460090 -0.613994  ...  0.383434  0.293486 -0.111097   \n",
       "V3     -0.306339  0.431457  0.722074  ... -0.206522 -0.313298  0.140931   \n",
       "V4      0.326635 -0.302267 -0.391789  ...  0.214640  0.223206 -0.032883   \n",
       "V5     -0.220784 -0.027481  0.066488  ...  0.084219 -0.274459 -0.163565   \n",
       "V6      0.160968  0.278992  0.488596  ... -0.216881 -0.125992  0.270270   \n",
       "V7     -0.607770  0.263959  0.573996  ... -0.134959 -0.521971 -0.149689   \n",
       "V8      1.000000 -0.226640 -0.450971  ...  0.137628  0.247115  0.173057   \n",
       "V9     -0.226640  1.000000  0.258399  ... -0.189115 -0.246892  0.108230   \n",
       "V10    -0.450971  0.258399  1.000000  ... -0.330711 -0.491226  0.045169   \n",
       "V11     0.386819 -0.473168 -0.577891  ...  0.258638  0.387545 -0.004765   \n",
       "V12    -0.422350  0.507992  0.756915  ... -0.339283 -0.469251  0.027774   \n",
       "V13    -0.242191 -0.058788  0.069906  ...  0.145848 -0.085179  0.017067   \n",
       "V14    -0.351765  0.442819  0.833678  ... -0.394361 -0.402651  0.032559   \n",
       "V15    -0.146436 -0.014149  0.076537  ...  0.063127 -0.027921 -0.037556   \n",
       "V16    -0.396564  0.224211  0.547964  ... -0.137428 -0.424934 -0.177923   \n",
       "V17    -0.329073  0.363619  0.530739  ... -0.331146 -0.529587 -0.069522   \n",
       "V18    -0.168181  0.007511  0.174440  ... -0.173415 -0.300471 -0.146002   \n",
       "V19     0.066067  0.001603 -0.023067  ...  0.453322  0.160571  0.152852   \n",
       "V20     0.137628 -0.189115 -0.330711  ...  1.000000  0.243477  0.068996   \n",
       "V21     0.247115 -0.246892 -0.491226  ...  0.243477  1.000000  0.630101   \n",
       "V22     0.173057  0.108230  0.045169  ...  0.068996  0.630101  1.000000   \n",
       "V23     0.041328  0.056700  0.105025  ... -0.119468 -0.203057 -0.221019   \n",
       "V24    -0.259863  0.062905  0.084824  ... -0.041165  0.063967  0.035967   \n",
       "V25    -0.073169  0.063168 -0.070467  ... -0.169757 -0.018456 -0.075476   \n",
       "V26     0.059990  0.003346 -0.010258  ...  0.033061 -0.080676 -0.158294   \n",
       "V27     0.389636 -0.316286 -0.517305  ...  0.469465  0.344696  0.016807   \n",
       "V28     0.318754 -0.312400 -0.389306  ...  0.155939  0.216135 -0.079816   \n",
       "Amount -0.023768  0.021961  0.079090  ...  0.138114  0.085301  0.116273   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "V1      0.033627 -0.031837  0.553666 -0.040292 -0.145427 -0.027116 -0.050507  \n",
       "V2     -0.127889  0.004079 -0.160697 -0.063708  0.469521  0.273470 -0.310984  \n",
       "V3      0.038129  0.201423 -0.271572  0.067682 -0.458994 -0.343049  0.081195  \n",
       "V4     -0.035522  0.032609  0.169180 -0.078656  0.356014  0.252866 -0.138690  \n",
       "V5     -0.146238 -0.386069 -0.099994 -0.195626 -0.102478 -0.106127 -0.242000  \n",
       "V6     -0.094205 -0.444513 -0.004464 -0.009125 -0.219925 -0.215934  0.201458  \n",
       "V7      0.005679  0.054669 -0.190029 -0.106753 -0.449265 -0.357647  0.022993  \n",
       "V8      0.041328 -0.259863 -0.073169  0.059990  0.389636  0.318754 -0.023768  \n",
       "V9      0.056700  0.062905  0.063168  0.003346 -0.316286 -0.312400  0.021961  \n",
       "V10     0.105025  0.084824 -0.070467 -0.010258 -0.517305 -0.389306  0.079090  \n",
       "V11     0.042407  0.042191  0.011532 -0.081003  0.431903  0.256637 -0.100133  \n",
       "V12     0.096737  0.102180  0.006832 -0.052746 -0.541412 -0.371929  0.064159  \n",
       "V13     0.004155 -0.049906  0.050820  0.046721 -0.097055 -0.009827  0.071644  \n",
       "V14     0.150149  0.088664 -0.109379 -0.025513 -0.544174 -0.364835  0.096556  \n",
       "V15     0.178481 -0.118216 -0.091227  0.010227  0.029423  0.056418  0.018250  \n",
       "V16    -0.060972  0.016367  0.069206  0.023017 -0.400483 -0.168937 -0.070891  \n",
       "V17     0.077769  0.021058  0.004983 -0.036736 -0.402241 -0.229835 -0.037230  \n",
       "V18    -0.180608 -0.050355  0.023086 -0.050457 -0.126527 -0.014515 -0.008742  \n",
       "V19    -0.134813  0.019563 -0.140213 -0.030405  0.102724 -0.049347  0.100247  \n",
       "V20    -0.119468 -0.041165 -0.169757  0.033061  0.469465  0.155939  0.138114  \n",
       "V21    -0.203057  0.063967 -0.018456 -0.080676  0.344696  0.216135  0.085301  \n",
       "V22    -0.221019  0.035967 -0.075476 -0.158294  0.016807 -0.079816  0.116273  \n",
       "V23     1.000000  0.263934 -0.431161  0.133757 -0.050846 -0.038727  0.057335  \n",
       "V24     0.263934  1.000000 -0.151414  0.107628 -0.092365 -0.038297 -0.057971  \n",
       "V25    -0.431161 -0.151414  1.000000 -0.188639 -0.036780  0.083193 -0.049407  \n",
       "V26     0.133757  0.107628 -0.188639  1.000000 -0.093488  0.013323  0.074653  \n",
       "V27    -0.050846 -0.092365 -0.036780 -0.093488  1.000000  0.652175 -0.117867  \n",
       "V28    -0.038727 -0.038297  0.083193  0.013323  0.652175  1.000000 -0.039668  \n",
       "Amount  0.057335 -0.057971 -0.049407  0.074653 -0.117867 -0.039668  1.000000  \n",
       "\n",
       "[29 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('V4', 'V5', 'V6', 'V8', 'V11', 'V15', 'V25', 'V28', 'Amount'),\n",
       " ('V1', 'V4', 'V5', 'V9', 'V18', 'V20', 'V21', 'V23', 'V26', 'Amount'),\n",
       " ('V1', 'V4', 'V5', 'V8', 'V9', 'V15', 'V19', 'V21', 'V27', 'Amount'),\n",
       " ('V4', 'V5', 'V9', 'V13', 'V15', 'V17', 'V20', 'V22', 'V23', 'Amount'),\n",
       " ('V1', 'V4', 'V5', 'V8', 'V13', 'V17', 'V22', 'V23', 'Amount'),\n",
       " ('V4', 'V8', 'V11', 'V13', 'V18', 'V22', 'V23', 'V24', 'V26'),\n",
       " ('V1', 'V4', 'V5', 'V6', 'V9', 'V15', 'V17', 'V18', 'V19', 'Amount'),\n",
       " ('V1', 'V13', 'V14', 'V23', 'V28', 'Amount'),\n",
       " ('V5', 'V11', 'V15', 'V18', 'V22', 'V24', 'V26', 'Amount'),\n",
       " ('V5', 'V12', 'V15', 'V19', 'V24', 'V26', 'V28', 'Amount')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "# Combinaciones de 3 y 4 columnas\n",
    "all_columns = X_new.columns\n",
    "combinations_6 = list(combinations(all_columns, 6))\n",
    "combinations_7 = list(combinations(all_columns, 7))\n",
    "combinations_8 = list(combinations(all_columns, 8))\n",
    "combinations_9 = list(combinations(all_columns, 9))\n",
    "combinations_10 = list(combinations(all_columns, 10))\n",
    "\n",
    "# Todas las posibles combinaciones\n",
    "all_combinations = combinations_6 + combinations_7 + combinations_8 + combinations_9 + combinations_10\n",
    "\n",
    "#Se hace un shuffle de las combinaciones\n",
    "rng = np.random.default_rng(seed=8172398273)\n",
    "rng.shuffle(all_combinations)\n",
    "\n",
    "# Se seleccionan las primeras 10 combinaciones que cumplan con el criterio de correlación de (-0.4, 0.4)\n",
    "selected_combinations = []\n",
    "for combination in all_combinations:\n",
    "    subset = X_new[list(combination)]\n",
    "    corr_matrix = subset.corr()\n",
    "    np.fill_diagonal(corr_matrix.values, 0)\n",
    "\n",
    "    if ((corr_matrix.abs() >= -0.4).all().all() and (corr_matrix.abs() <= 0.4)).all().all():\n",
    "        selected_combinations.append(combination)\n",
    "    if len(selected_combinations) >= 10:\n",
    "        break\n",
    "\n",
    "selected_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ('V4', 'V5', 'V6', 'V8', 'V11', 'V15', 'V25', 'V28', 'Amount'), Score: 0.9613259668508287\n",
      "Columns: ('V1', 'V4', 'V5', 'V9', 'V18', 'V20', 'V21', 'V23', 'V26', 'Amount'), Score: 0.9281767955801105\n",
      "Columns: ('V1', 'V4', 'V5', 'V8', 'V9', 'V15', 'V19', 'V21', 'V27', 'Amount'), Score: 0.9226519337016574\n",
      "Columns: ('V4', 'V5', 'V9', 'V13', 'V15', 'V17', 'V20', 'V22', 'V23', 'Amount'), Score: 0.9226519337016574\n",
      "Columns: ('V1', 'V4', 'V5', 'V8', 'V13', 'V17', 'V22', 'V23', 'Amount'), Score: 0.9337016574585635\n",
      "Columns: ('V4', 'V8', 'V11', 'V13', 'V18', 'V22', 'V23', 'V24', 'V26'), Score: 0.9558011049723757\n",
      "Columns: ('V1', 'V4', 'V5', 'V6', 'V9', 'V15', 'V17', 'V18', 'V19', 'Amount'), Score: 0.9447513812154696\n",
      "Columns: ('V1', 'V13', 'V14', 'V23', 'V28', 'Amount'), Score: 0.9613259668508287\n",
      "Columns: ('V5', 'V11', 'V15', 'V18', 'V22', 'V24', 'V26', 'Amount'), Score: 0.9281767955801105\n",
      "Columns: ('V5', 'V12', 'V15', 'V19', 'V24', 'V26', 'V28', 'Amount'), Score: 0.9613259668508287\n",
      "==================================================\n",
      "MODELO 1\n",
      "Columnas: ('V4', 'V5', 'V6', 'V8', 'V11', 'V15', 'V25', 'V28', 'Amount') con un score de 0.9613259668508287\n",
      "\n",
      "==================================================\n",
      "MODELO 2\n",
      "Columnas: ('V1', 'V4', 'V5', 'V9', 'V18', 'V20', 'V21', 'V23', 'V26', 'Amount') con un score de 0.9281767955801105\n",
      "\n",
      "==================================================\n",
      "MODELO 3\n",
      "Columnas: ('V1', 'V4', 'V5', 'V8', 'V9', 'V15', 'V19', 'V21', 'V27', 'Amount') con un score de 0.9226519337016574\n",
      "\n",
      "==================================================\n",
      "MODELO 4\n",
      "Columnas: ('V4', 'V5', 'V9', 'V13', 'V15', 'V17', 'V20', 'V22', 'V23', 'Amount') con un score de 0.9226519337016574\n",
      "\n",
      "==================================================\n",
      "MODELO 5\n",
      "Columnas: ('V1', 'V4', 'V5', 'V8', 'V13', 'V17', 'V22', 'V23', 'Amount') con un score de 0.9337016574585635\n",
      "\n",
      "==================================================\n",
      "MODELO 6\n",
      "Columnas: ('V4', 'V8', 'V11', 'V13', 'V18', 'V22', 'V23', 'V24', 'V26') con un score de 0.9558011049723757\n",
      "\n",
      "==================================================\n",
      "MODELO 7\n",
      "Columnas: ('V1', 'V4', 'V5', 'V6', 'V9', 'V15', 'V17', 'V18', 'V19', 'Amount') con un score de 0.9447513812154696\n",
      "\n",
      "==================================================\n",
      "MODELO 8\n",
      "Columnas: ('V1', 'V13', 'V14', 'V23', 'V28', 'Amount') con un score de 0.9613259668508287\n",
      "\n",
      "==================================================\n",
      "MODELO 9\n",
      "Columnas: ('V5', 'V11', 'V15', 'V18', 'V22', 'V24', 'V26', 'Amount') con un score de 0.9281767955801105\n",
      "\n",
      "==================================================\n",
      "MODELO 10\n",
      "Columnas: ('V5', 'V12', 'V15', 'V19', 'V24', 'V26', 'V28', 'Amount') con un score de 0.9613259668508287\n",
      "\n",
      "El mejor score es: 0.9613259668508287 con las columnas ('V4', 'V5', 'V6', 'V8', 'V11', 'V15', 'V25', 'V28', 'Amount')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\santi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "log_regres = LogisticRegression()\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=45)\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Se entrena el modelo con cada combinación y se guarda el score\n",
    "for combination in selected_combinations:\n",
    "    log_regres.fit(x_train[list(combination)], y_train)\n",
    "    score = log_regres.score(x_test[list(combination)], y_test)\n",
    "    scores.append({\n",
    "        'combination': combination,\n",
    "        'score': score\n",
    "    })\n",
    "    print(f'Columns: {combination}, Score: {score}')\n",
    "\n",
    "# Se obtiene la mejor combinación que tiene el mayor score\n",
    "best_score = max(scores, key=lambda x: x['score'])\n",
    "\n",
    "for index, score in enumerate(scores):\n",
    "    print(\"=\"*50)\n",
    "    print(f'MODELO {index+1}')\n",
    "    print(f'Columnas: {score[\"combination\"]} con un score de {score[\"score\"]}\\n')\n",
    "\n",
    "print(f'El mejor score es: {best_score[\"score\"]} con las columnas {best_score[\"combination\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REGRESIÓN LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraciones: 50, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 50, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 51, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 51, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 52, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 52, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 53, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 53, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 54, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 54, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 55, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 55, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 56, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 56, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 57, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 57, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 58, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 58, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 59, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 59, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 60, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 60, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 61, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 61, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 62, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 62, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 63, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 63, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 64, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 64, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 65, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 65, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 66, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 66, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 67, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 67, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 68, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 68, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 69, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 69, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 70, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 70, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 71, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 71, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 72, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 72, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 73, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 73, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 74, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 74, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 75, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 75, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 76, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 76, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 77, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 77, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 78, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 78, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 79, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 79, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 80, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 80, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 81, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 81, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 82, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 82, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 83, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 83, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 84, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 84, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 85, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 85, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 86, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 86, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 87, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 87, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 88, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 88, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 89, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 89, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 90, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 90, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 91, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 91, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 92, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 92, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 93, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 93, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 94, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 94, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 95, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 95, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 96, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 96, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 97, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 97, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 98, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 98, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 99, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 99, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 100, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 100, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 101, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 101, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 102, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 102, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 103, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 103, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 104, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 104, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 105, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 105, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 106, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 106, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 107, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 107, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 108, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 108, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 109, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 109, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 110, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 110, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 111, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 111, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 112, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 112, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 113, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 113, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 114, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 114, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 115, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 115, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 116, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 116, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 117, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 117, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 118, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 118, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 119, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 119, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 120, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 120, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 121, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 121, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 122, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 122, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 123, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 123, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 124, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 124, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 125, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 125, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 126, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 126, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 127, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 127, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 128, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 128, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 129, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 129, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 130, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 130, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 131, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 131, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 132, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 132, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 133, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 133, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 134, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 134, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 135, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 135, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 136, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 136, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 137, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 137, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 138, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 138, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 139, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 139, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 140, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 140, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 141, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 141, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 142, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 142, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 143, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 143, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 144, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 144, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 145, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 145, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 146, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 146, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 147, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 147, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 148, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 148, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 149, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 149, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 150, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 150, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 151, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 151, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 152, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 152, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 153, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 153, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 154, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 154, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 155, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 155, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 156, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 156, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 157, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 157, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 158, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 158, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 159, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 159, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 160, Solver: liblinear, Penalty: l1\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 160, Solver: liblinear, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 50, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 50, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 51, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 51, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 52, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 52, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 53, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 53, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 54, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 54, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 55, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 55, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 56, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 56, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 57, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 57, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 58, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 58, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 59, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 59, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 60, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 60, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 61, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 61, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 62, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 62, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 63, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 63, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 64, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 64, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 65, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 65, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 66, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 66, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 67, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 67, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 68, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 68, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 69, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 69, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 70, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 70, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 71, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 71, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 72, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 72, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 73, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 73, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 74, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 74, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 75, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 75, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 76, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 76, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 77, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 77, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 78, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 78, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 79, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 79, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 80, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 80, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 81, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 81, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 82, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 82, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 83, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 83, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 84, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 84, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 85, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 85, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 86, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 86, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 87, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 87, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 88, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 88, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 89, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 89, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 90, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 90, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 91, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 91, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 92, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 92, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 93, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 93, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 94, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 94, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 95, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 95, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 96, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 96, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 97, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 97, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 98, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 98, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 99, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 99, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 100, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 100, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 101, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 101, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 102, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 102, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 103, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 103, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 104, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 104, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 105, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 105, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 106, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 106, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 107, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 107, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 108, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 108, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 109, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 109, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 110, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 110, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 111, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 111, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 112, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 112, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 113, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 113, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 114, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 114, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 115, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 115, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 116, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 116, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 117, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 117, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 118, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 118, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 119, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 119, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 120, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 120, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 121, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 121, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 122, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 122, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 123, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 123, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 124, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 124, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 125, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 125, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 126, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 126, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 127, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 127, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 128, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 128, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 129, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 129, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 130, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 130, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 131, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 131, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 132, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 132, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 133, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 133, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 134, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 134, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 135, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 135, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 136, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 136, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 137, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 137, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 138, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 138, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 139, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 139, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 140, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 140, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 141, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 141, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 142, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 142, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 143, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 143, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 144, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 144, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 145, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 145, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 146, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 146, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 147, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 147, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 148, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 148, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 149, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 149, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 150, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 150, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 151, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 151, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 152, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 152, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 153, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 153, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 154, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 154, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 155, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 155, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 156, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 156, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 157, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 157, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 158, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 158, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 159, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 159, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 160, Solver: newton-cholesky, Penalty: l2\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "Iteraciones: 160, Solver: newton-cholesky, Penalty: None\n",
      "---> Score: 0.9613259668508287\n",
      "\n",
      "El mejor score, con optimizacion de hiperparametros es: 0.9613259668508287 con la combinación (50, 'liblinear', 'l1')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Se preparan los hiperparametros basados en lo especificado\n",
    "iterations_max = np.arange(50, 161, 1)\n",
    "solver = ['liblinear']\n",
    "penalty = ['l1', 'l2']\n",
    "combinations_1 = list(itertools.product(iterations_max, solver, penalty))\n",
    "\n",
    "solver = ['newton-cholesky']\n",
    "penalty = ['l2', None]\n",
    "combinations_2 = list(itertools.product(iterations_max, solver, penalty))\n",
    "\n",
    "combinations = combinations_1 + combinations_2\n",
    "\n",
    "x_train = x_train[list(best_score['combination'])]\n",
    "x_test = x_test[list(best_score['combination'])]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Se entrena el modelo con cada combinación de hiperparámetros y se guarda el score\n",
    "for combination in combinations:\n",
    "    try:\n",
    "        logistic = LogisticRegression(max_iter=combination[0], solver=combination[1], penalty=combination[2])\n",
    "        logistic.fit(x_train, y_train)\n",
    "\n",
    "        print(f'Iteraciones: {combination[0]}, Solver: {combination[1]}, Penalty: {combination[2]}')\n",
    "\n",
    "        score = logistic.score(x_test, y_test)\n",
    "        print(f'---> Score: {score}\\n')\n",
    "        results.append({\n",
    "            'combination': combination,\n",
    "            'score': score\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "\n",
    "# Se obtiene la mejor combinación que tiene el mayor score\n",
    "best_score = max(results, key=lambda x: x['score'])\n",
    "print(f'El mejor score, con optimizacion de hiperparametros es: {best_score[\"score\"]} con la combinación {best_score[\"combination\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÁRBOLES DE DECISIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': list(range(5, 13)),\n",
    "    'min_samples_split': list(range(20, 22)),\n",
    "    'min_samples_leaf': list(range(7, 16)),\n",
    "    'max_leaf_nodes': list(range(5, 10))\n",
    "}\n",
    "\n",
    "combinations = list(itertools.product(parameters['max_depth'], parameters['min_samples_split'], parameters['min_samples_leaf'], parameters['max_leaf_nodes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MEJOR MODELO es max_depth: 5, min_samples_split: 20, min_samples_leaf: 11, max_leaf_nodes: 5\n",
      "El score es de: 0.9668508287292817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "scores = []\n",
    "\n",
    "for comb in combinations:\n",
    "  tree_model=DecisionTreeClassifier(criterion='gini', max_depth=comb[0], min_samples_split=comb[1], min_samples_leaf=comb[2], max_leaf_nodes=comb[3])\n",
    "  tree_model=tree_model.fit(x_train,y_train)\n",
    "  scores.append({\n",
    "    'combination': comb,\n",
    "    'score': tree_model.score(x_test, y_test)\n",
    "  })\n",
    "\n",
    "best_score = max(scores, key=lambda x: x['score'])\n",
    "\n",
    "print(f'El MEJOR MODELO es max_depth: {best_score[\"combination\"][0]}, min_samples_split: {best_score[\"combination\"][1]}, min_samples_leaf: {best_score[\"combination\"][2]}, max_leaf_nodes: {best_score[\"combination\"][3]}')\n",
    "print(f'El score es de: {best_score[\"score\"]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOSQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_parameters = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': list(range(2, 8)),\n",
    "    'min_samples_split': list(range(5, 11)),\n",
    "    'n_estimators': [60, 76, 92, 108, 124, 140, 156, 172, 188, 204, 220, 236, 252, 268, 284]\n",
    "}\n",
    "\n",
    "combinations = list(itertools.product(forest_parameters['criterion'], forest_parameters['max_depth'], forest_parameters['min_samples_split'], forest_parameters['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08450af1e69640f6837790f3326591cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "scores = []\n",
    "\n",
    "def train_forest(comb):\n",
    "    model = RandomForestClassifier(\n",
    "        criterion=comb[0],\n",
    "        max_depth=comb[1],\n",
    "        min_samples_split=comb[2],\n",
    "        n_estimators=comb[3]\n",
    "    )\n",
    "    model.fit(x_train, y_train)\n",
    "    return model.score(x_test, y_test)\n",
    "\n",
    "def run_computation():\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
    "        futures = {executor.submit(train_forest, comb): comb for comb in combinations}\n",
    "\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            try:\n",
    "                scores.append(future.result())\n",
    "            except Exception as e:\n",
    "                print(f'Error processing future: {e}')\n",
    "\n",
    "run_computation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor score es: 0.9834254143646409 con la combinación ('gini', 3, 9, 76)\n"
     ]
    }
   ],
   "source": [
    "max_score = max(scores)\n",
    "index_max_score = scores.index(max_score)\n",
    "best_combination = combinations[index_max_score]\n",
    "\n",
    "print(f'El mejor score es: {max_score} con la combinación {best_combination}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=3, min_samples_split=9, n_estimators=76)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=3, min_samples_split=9, n_estimators=76)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=3, min_samples_split=9, n_estimators=76)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "log_model=LogisticRegression(max_iter=50, solver='liblinear', penalty='l1')\n",
    "log_model.fit(x_train,y_train)\n",
    "\n",
    "tree_model=DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=20, min_samples_leaf= 11, max_leaf_nodes= 5)\n",
    "tree_model.fit(x_train,y_train)\n",
    "\n",
    "forest_model=RandomForestClassifier(criterion='gini', max_depth=3, min_samples_split= 9, n_estimators= 76)\n",
    "forest_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logistic</th>\n",
       "      <th>trees</th>\n",
       "      <th>forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     logistic  trees  forest\n",
       "0         0.0    1.0     0.0\n",
       "1         1.0    1.0     1.0\n",
       "2         1.0    1.0     1.0\n",
       "3         0.0    0.0     0.0\n",
       "4         0.0    0.0     0.0\n",
       "..        ...    ...     ...\n",
       "176       0.0    0.0     0.0\n",
       "177       0.0    0.0     0.0\n",
       "178       0.0    0.0     0.0\n",
       "179       0.0    0.0     0.0\n",
       "180       0.0    0.0     0.0\n",
       "\n",
       "[181 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"logistic\":log_model.predict(x_test),\n",
    "    \"trees\":tree_model.predict(x_test),\n",
    "    \"forest\":forest_model.predict(x_test)\n",
    "}\n",
    "\n",
    "df_models = pd.DataFrame(models)\n",
    "\n",
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for AND Operation:\n",
      "[[162   0]\n",
      " [  8  11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions_and = ((df_models['logistic'] == 1) & (df_models['trees'] == 1) & (df_models['forest'] == 1)).astype(int)\n",
    "\n",
    "conf_matrix_and = confusion_matrix(y_test, predictions_and)\n",
    "\n",
    "print('Confusion Matrix for AND Operation:')\n",
    "print(conf_matrix_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for OR Operation:\n",
      "[[159   3]\n",
      " [  3  16]]\n"
     ]
    }
   ],
   "source": [
    "predictions_or = ((df_models['logistic'] == 1) | (df_models['trees'] == 1) | (df_models['forest'] == 1)).astype(int)\n",
    "\n",
    "conf_matrix_or = confusion_matrix(y_test, predictions_or)\n",
    "\n",
    "print('\\nConfusion Matrix for OR Operation:')\n",
    "print(conf_matrix_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix for Voting Operation:\n",
      "[[161   1]\n",
      " [  6  13]]\n"
     ]
    }
   ],
   "source": [
    "#el dos es para los votantes\n",
    "predictions_voting = ((df_models['logistic'] + df_models['trees'] + df_models['forest']) >= 2).astype(int)\n",
    "\n",
    "conf_matrix_voting = confusion_matrix(y_test, predictions_voting)\n",
    "\n",
    "print('\\nConfusion Matrix for Voting Operation:')\n",
    "print(conf_matrix_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "ddps = []\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, operation_name):\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    DDP=math.sqrt((1-specificity)**2+(1-sensitivity)**2)\n",
    "\n",
    "\n",
    "    print(f'\\nMetrics for {operation_name} Operation:')\n",
    "    print(f'Confusion Matrix:\\n[[TN: {tn}, FP: {fp}]\\n [FN: {fn}, TP: {tp}]]')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Sensitivity (Recall): {sensitivity:.4f}')\n",
    "    print(f'Specificity: {specificity:.4f}')\n",
    "    print(f'DDP: {DDP:.4f}')\n",
    "    ddps.append({\n",
    "        \"ddp\": DDP,\n",
    "        \"operation\": operation_name\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for AND Operation:\n",
      "Confusion Matrix:\n",
      "[[TN: 162, FP: 0]\n",
      " [FN: 8, TP: 11]]\n",
      "Accuracy: 0.9558\n",
      "Precision: 1.0000\n",
      "Sensitivity (Recall): 0.5789\n",
      "Specificity: 1.0000\n",
      "DDP: 0.4211\n",
      "\n",
      "Metrics for OR Operation:\n",
      "Confusion Matrix:\n",
      "[[TN: 159, FP: 3]\n",
      " [FN: 3, TP: 16]]\n",
      "Accuracy: 0.9669\n",
      "Precision: 0.8421\n",
      "Sensitivity (Recall): 0.8421\n",
      "Specificity: 0.9815\n",
      "DDP: 0.1590\n",
      "\n",
      "Metrics for Voting Operation:\n",
      "Confusion Matrix:\n",
      "[[TN: 161, FP: 1]\n",
      " [FN: 6, TP: 13]]\n",
      "Accuracy: 0.9613\n",
      "Precision: 0.9286\n",
      "Sensitivity (Recall): 0.6842\n",
      "Specificity: 0.9938\n",
      "DDP: 0.3158\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(y_test, predictions_and, 'AND')\n",
    "calculate_metrics(y_test, predictions_or, 'OR')\n",
    "calculate_metrics(y_test, predictions_voting, 'Voting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo es OR con un DDP de: 0.1589769903179652\n"
     ]
    }
   ],
   "source": [
    "best_ddp = min(ddps, key=lambda x: x['ddp'])\n",
    "print(f\"El mejor modelo es {best_ddp['operation']} con un DDP de: {best_ddp['ddp']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El DDP calcula la distancia de detección perfecta. Es por ello por lo que se busca la menor distancia entre 0 (la distancia perfecta) y el cálulo basado en la distancia euclidiana entre la sensibilidad y la especificidad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
